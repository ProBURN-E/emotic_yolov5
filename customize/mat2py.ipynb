{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Annotations\n",
      "starting label  train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing data: 100%|██████████| 17077/17077 [09:07<00:00, 31.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 0 359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing csv file: 100%|██████████| 23266/23266 [00:00<00:00, 37086.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote file  E:\\Download\\emotic_dataset\\emotic_pre\\train.csv\n",
      "23266 (23266, 224, 224, 3) (23266, 128, 128, 3)\n",
      "(23266, 224, 224, 3) (23266, 128, 128, 3) (23266, 26) (23266, 3)\n",
      "completed generating train data files\n",
      "starting label  val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing data: 100%|██████████| 2088/2088 [01:09<00:00, 29.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing csv file: 100%|██████████| 3315/3315 [00:00<00:00, 87307.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote file  E:\\Download\\emotic_dataset\\emotic_pre\\val.csv\n",
      "3315 (3315, 224, 224, 3) (3315, 128, 128, 3)\n",
      "(3315, 224, 224, 3) (3315, 128, 128, 3) (3315, 26) (3315, 3)\n",
      "completed generating val data files\n",
      "starting label  test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing data: 100%|██████████| 4389/4389 [02:10<00:00, 33.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 0 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing csv file: 100%|██████████| 7203/7203 [00:00<00:00, 109081.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote file  E:\\Download\\emotic_dataset\\emotic_pre\\test.csv\n",
      "7203 (7203, 224, 224, 3) (7203, 128, 128, 3)\n",
      "(7203, 224, 224, 3) (7203, 128, 128, 3) (7203, 26) (7203, 3)\n",
      "completed generating test data files\n"
     ]
    }
   ],
   "source": [
    "import argparse \n",
    "import csv \n",
    "import cv2\n",
    "import numpy as np \n",
    "import os \n",
    "from scipy.io import loadmat \n",
    "from tqdm import tqdm\n",
    "\n",
    "class emotic_train:\n",
    "    def __init__(self, filename, folder, image_size, person):\n",
    "        self.filename = filename\n",
    "        self.folder = folder\n",
    "        self.im_size = []\n",
    "        self.bbox = []\n",
    "        self.cat = []\n",
    "        self.cont = []\n",
    "        self.gender = person[3][0]\n",
    "        self.age = person[4][0]\n",
    "        self.cat_annotators = 0\n",
    "        self.cont_annotators = 0\n",
    "        self.set_imsize(image_size)\n",
    "        self.set_bbox(person[0])\n",
    "        self.set_cat(person[1])\n",
    "        self.set_cont(person[2])\n",
    "        self.check_cont()\n",
    "\n",
    "    def set_imsize(self, image_size):\n",
    "        image_size = np.array(image_size).flatten().tolist()[0]\n",
    "        row = np.array(image_size[0]).flatten().tolist()[0]\n",
    "        col = np.array(image_size[1]).flatten().tolist()[0]\n",
    "        self.im_size.append(row)\n",
    "        self.im_size.append(col)\n",
    "\n",
    "    def validate_bbox(self, bbox):\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        x1 = min(self.im_size[0], max(0, x1))\n",
    "        x2 = min(self.im_size[0], max(0, x2))\n",
    "        y1 = min(self.im_size[1], max(0, y1))\n",
    "        y2 = min(self.im_size[1], max(0, y2))\n",
    "        return [int(x1), int(y1), int(x2), int(y2)]\n",
    "\n",
    "    def set_bbox(self, person_bbox):\n",
    "        self.bbox = self.validate_bbox(np.array(person_bbox).flatten().tolist())\n",
    "\n",
    "    def set_cat(self, person_cat):\n",
    "        cat = np.array(person_cat).flatten().tolist()\n",
    "        cat = np.array(cat[0]).flatten().tolist()\n",
    "        self.cat = [np.array(c).flatten().tolist()[0] for c in cat]\n",
    "        self.cat_annotators = 1\n",
    "\n",
    "    def set_cont(self, person_cont):\n",
    "        cont = np.array(person_cont).flatten().tolist()[0]\n",
    "        self.cont = [np.array(c).flatten().tolist()[0] for c in cont]\n",
    "        self.cont_annotators = 1\n",
    "\n",
    "    def check_cont(self):\n",
    "        for c in self.cont:\n",
    "            if np.isnan(c):\n",
    "                self.cont_annotators = 0\n",
    "                break\n",
    "\n",
    "class emotic_test:\n",
    "    def __init__(self, filename, folder, image_size, person):\n",
    "        self.filename = filename\n",
    "        self.folder = folder\n",
    "        self.im_size = []\n",
    "        self.bbox = []\n",
    "        self.cat = []\n",
    "        self.cat_annotators = 0\n",
    "        self.comb_cat = []\n",
    "        self.cont_annotators = 0\n",
    "        self.cont = []\n",
    "        self.comb_cont = []\n",
    "        self.gender = person[5][0]\n",
    "        self.age = person[6][0]\n",
    "\n",
    "        self.set_imsize(image_size)\n",
    "        self.set_bbox(person[0])\n",
    "        self.set_cat(person[1])\n",
    "        self.set_comb_cat(person[2])\n",
    "        self.set_cont(person[3])\n",
    "        self.set_comb_cont(person[4])\n",
    "        self.check_cont()\n",
    "\n",
    "    def set_imsize(self, image_size):\n",
    "        image_size = np.array(image_size).flatten().tolist()[0]\n",
    "        row = np.array(image_size[0]).flatten().tolist()[0]\n",
    "        col = np.array(image_size[1]).flatten().tolist()[0]\n",
    "        self.im_size.append(row)\n",
    "        self.im_size.append(col)\n",
    "\n",
    "    def validate_bbox(self, bbox):\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        x1 = min(self.im_size[0], max(0, x1))\n",
    "        x2 = min(self.im_size[0], max(0, x2))\n",
    "        y1 = min(self.im_size[1], max(0, y1))\n",
    "        y2 = min(self.im_size[1], max(0, y2))\n",
    "        return [int(x1), int(y1), int(x2), int(y2)]\n",
    "\n",
    "    def set_bbox(self, person_bbox):\n",
    "        self.bbox = self.validate_bbox(np.array(person_bbox).flatten().tolist())\n",
    "\n",
    "    def set_cat(self, person_cat):\n",
    "        self.cat_annotators = len(person_cat[0])\n",
    "        for ann in range(self.cat_annotators):\n",
    "            ann_cat = person_cat[0][ann]\n",
    "            ann_cat = np.array(ann_cat).flatten().tolist()\n",
    "            ann_cat = np.array(ann_cat[0]).flatten().tolist()\n",
    "            ann_cat = [np.array(c).flatten().tolist()[0] for c in ann_cat]\n",
    "            self.cat.append(ann_cat)\n",
    "\n",
    "    def set_comb_cat(self, person_comb_cat):\n",
    "        if self.cat_annotators != 0:\n",
    "            self.comb_cat = [np.array(c).flatten().tolist()[0] for c in person_comb_cat[0]]\n",
    "        else:\n",
    "            self.comb_cat = []\n",
    "\n",
    "    def set_comb_cont(self, person_comb_cont):\n",
    "        if self.cont_annotators != 0:\n",
    "            comb_cont = [np.array(c).flatten().tolist()[0] for c in person_comb_cont[0]]\n",
    "            self.comb_cont = [np.array(c).flatten().tolist()[0] for c in comb_cont[0]]\n",
    "        else:\n",
    "            self.comb_cont = []\n",
    "\n",
    "    def set_cont(self, person_cont):\n",
    "        self.cont_annotators = len(person_cont[0])\n",
    "        for ann in range(self.cont_annotators):\n",
    "            ann_cont = person_cont[0][ann]\n",
    "            ann_cont = np.array(ann_cont).flatten().tolist()\n",
    "            ann_cont = np.array(ann_cont[0]).flatten().tolist()\n",
    "            ann_cont = [np.array(c).flatten().tolist()[0] for c in ann_cont]\n",
    "            self.cont.append(ann_cont)\n",
    "\n",
    "    def check_cont(self):\n",
    "        for c in self.comb_cont:\n",
    "            if np.isnan(c):\n",
    "                self.cont_annotators = 0\n",
    "                break\n",
    "\n",
    "\n",
    "def cat_to_one_hot(y_cat):\n",
    "    '''\n",
    "    One hot encode a categorical label. \n",
    "    :param y_cat: Categorical label.\n",
    "    :return: One hot encoded categorical label. \n",
    "    '''\n",
    "    one_hot_cat = np.zeros(26)\n",
    "    for em in y_cat:\n",
    "        one_hot_cat[cat2ind[em]] = 1\n",
    "    return one_hot_cat\n",
    "\n",
    "def prepare_data(data_mat, data_path_src, save_dir, dataset_type='train', generate_npy=False, debug_mode=False):\n",
    "  '''\n",
    "  Prepare csv files and save preprocessed data in npy files. \n",
    "  :param data_mat: Mat data object for a label. \n",
    "  :param data_path_src: Path of the parent directory containing the emotic images folders (mscoco, framesdb, emodb_small, ade20k)\n",
    "  :param save_dir: Path of the directory to save the csv files and the npy files (if generate_npy files is True)\n",
    "  :param dataset_type: Type of the dataset (train, val or test). Variable used in the name of csv files and npy files. \n",
    "  :param generate_npy: If True the data is preprocessed and saved in npy files. Npy files are later used for training. \n",
    "  '''\n",
    "  data_set = list()\n",
    "\n",
    "  if generate_npy:\n",
    "    context_arr = list()\n",
    "    body_arr = list()\n",
    "    cat_arr = list()\n",
    "    cont_arr = list()\n",
    "  \n",
    "  to_break = 0\n",
    "  path_not_exist = 0\n",
    "  cat_cont_zero = 0\n",
    "  idx = 0\n",
    "  for ex_idx, ex in enumerate(tqdm(data_mat[0],desc='Preparing data')):\n",
    "    nop = len(ex[4][0])\n",
    "    for person in range(nop):\n",
    "      if dataset_type == 'train':\n",
    "        et = emotic_train(ex[0][0],ex[1][0],ex[2],ex[4][0][person])\n",
    "      else:\n",
    "        et = emotic_test(ex[0][0],ex[1][0],ex[2],ex[4][0][person])\n",
    "      try:\n",
    "        image_path = os.path.join(data_path_src,et.folder,et.filename)\n",
    "        if not os.path.exists(image_path):\n",
    "          path_not_exist += 1\n",
    "          print ('path not existing', ex_idx, image_path)\n",
    "          continue\n",
    "        else:\n",
    "          context = cv2.cvtColor(cv2.imread(image_path),cv2.COLOR_BGR2RGB)\n",
    "          body = context[et.bbox[1]:et.bbox[3],et.bbox[0]:et.bbox[2]].copy()\n",
    "          context_cv = cv2.resize(context, (224,224))\n",
    "          body_cv = cv2.resize(body, (128,128))\n",
    "          try:\n",
    "             assert context_cv.shape[2] == 3\n",
    "          except AssertionError:\n",
    "             context_cv = context_cv[:,:,:3]\n",
    "             print ('context_cv.shape[2] != 3', context_cv.shape[2])\n",
    "          try:\n",
    "             assert body_cv.shape[2] == 3\n",
    "          except AssertionError:\n",
    "              body_cv = body_cv[:,:,:3]\n",
    "              print ('body_cv.shape[2] != 3', body_cv.shape[2])\n",
    "      except Exception as e:\n",
    "        to_break += 1\n",
    "        if debug_mode == True:\n",
    "            print ('breaking at idx=%d, %d due to exception=%r' %(ex_idx, idx, e))\n",
    "        continue\n",
    "      if (et.cat_annotators == 0 or et.cont_annotators == 0):\n",
    "        cat_cont_zero += 1\n",
    "        continue\n",
    "      data_set.append(et)  \n",
    "      if generate_npy == True:\n",
    "        context_arr.append(context_cv)\n",
    "        body_arr.append(body_cv)\n",
    "        if dataset_type == 'train':\n",
    "          cat_arr.append(cat_to_one_hot(et.cat))\n",
    "          cont_arr.append(np.array(et.cont))\n",
    "        else: \n",
    "          cat_arr.append(cat_to_one_hot(et.comb_cat))\n",
    "          cont_arr.append(np.array(et.comb_cont))\n",
    "      # if idx % 1000 == 0 and debug_mode==False:\n",
    "      #   print (\" Preprocessing data. Index = \", idx)\n",
    "      # elif idx % 20 == 0 and debug_mode==True:\n",
    "      #   print (\" Preprocessing data. Index = \", idx)\n",
    "      # idx = idx + 1\n",
    "    # for debugging purposes\n",
    "    if debug_mode == True and idx >= 104:\n",
    "      print (' ######## Breaking data prep step', idx, ex_idx, ' ######')\n",
    "      print (to_break, path_not_exist, cat_cont_zero)\n",
    "      cv2.imwrite(os.path.join(save_dir, 'context1.png'), context_arr[-1])\n",
    "      cv2.imwrite(os.path.join(save_dir, 'body1.png'), body_arr[-1])\n",
    "      break\n",
    "  print (to_break, path_not_exist, cat_cont_zero)\n",
    "  \n",
    "  csv_path = os.path.join(save_dir, \"%s.csv\" %(dataset_type))\n",
    "  with open(csv_path, 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',', dialect='excel')\n",
    "    row = ['Index', 'Folder', 'Filename', 'Image Size', 'BBox', 'Categorical_Labels', 'Continuous_Labels', 'Gender', 'Age']\n",
    "    filewriter.writerow(row)\n",
    "    for idx, ex in enumerate(tqdm(data_set,desc='Writing csv file')):\n",
    "        if dataset_type == 'train':\n",
    "            row = [idx, ex.folder, ex.filename, ex.im_size, ex.bbox, ex.cat, ex.cont, ex.gender, ex.age]\n",
    "        else:\n",
    "            row = [idx, ex.folder, ex.filename, ex.im_size, ex.bbox, ex.comb_cat, ex.comb_cont, ex.gender, ex.age]\n",
    "        filewriter.writerow(row)\n",
    "  print ('wrote file ', csv_path)\n",
    "\n",
    "  if generate_npy == True: \n",
    "    context_arr = np.array(context_arr)\n",
    "    body_arr = np.array(body_arr)\n",
    "    cat_arr = np.array(cat_arr)\n",
    "    cont_arr = np.array(cont_arr)\n",
    "    print (len(data_set), context_arr.shape, body_arr.shape)\n",
    "    np.save(os.path.join(save_dir,'%s_context_arr.npy' %(dataset_type)), context_arr)\n",
    "    np.save(os.path.join(save_dir,'%s_body_arr.npy' %(dataset_type)), body_arr)\n",
    "    np.save(os.path.join(save_dir,'%s_cat_arr.npy' %(dataset_type)), cat_arr)\n",
    "    np.save(os.path.join(save_dir,'%s_cont_arr.npy' %(dataset_type)), cont_arr)\n",
    "    print (context_arr.shape, body_arr.shape, cat_arr.shape, cont_arr.shape)\n",
    "  print ('completed generating %s data files' %(dataset_type))\n",
    " \n",
    "\n",
    "# def parse_args():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--data_dir', type=str, required=True, help='Path to Emotic data and annotations')\n",
    "#     parser.add_argument('--save_dir_name', type=str, default='emotic_pre', help='Directory name in which preprocessed data will be stored')\n",
    "#     parser.add_argument('--label', type=str,  default='all', choices=['train', 'val', 'test', 'all'])\n",
    "#     parser.add_argument('--generate_npy', action='store_true', help='Generate npy files')\n",
    "#     parser.add_argument('--debug_mode', action='store_true', help='Debug mode. Will only save a small subset of the data')\n",
    "#     # Generate args\n",
    "#     args = parser.parse_args()\n",
    "#     return args\n",
    "class parse_args:\n",
    "    def __init__(self):\n",
    "        self.data_dir = 'E:\\Download\\emotic_dataset'\n",
    "        self.save_dir_name = 'emotic_pre'\n",
    "        self.label = 'all'\n",
    "        self.generate_npy = True\n",
    "        self.debug_mode = False\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    ann_path_src = os.path.join(args.data_dir, 'Annotations.mat')\n",
    "    data_path_src = os.path.join(args.data_dir, 'emotic')\n",
    "    save_path = os.path.join(args.data_dir, args.save_dir_name)\n",
    "    if not os.path.exists(save_path):\n",
    "      os.makedirs(save_path)\n",
    "    \n",
    "    cat = ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion', 'Confidence', 'Disapproval', 'Disconnection',\n",
    "       'Disquietment', 'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem', 'Excitement', 'Fatigue', 'Fear',\n",
    "       'Happiness', 'Pain', 'Peace', 'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise', 'Sympathy', 'Yearning']\n",
    "    cat2ind = {}\n",
    "    ind2cat = {}\n",
    "    for idx, emotion in enumerate(cat):\n",
    "        cat2ind[emotion] = idx\n",
    "        ind2cat[idx] = emotion\n",
    "    \n",
    "    print ('loading Annotations')\n",
    "    mat = loadmat(ann_path_src)\n",
    "    if args.label.lower() == 'all':\n",
    "      labels = ['train', 'val', 'test']\n",
    "    else:\n",
    "      labels = [args.label.lower()]\n",
    "    for label in labels:\n",
    "      data_mat = mat[label]\n",
    "      print ('starting label ', label)\n",
    "      prepare_data(data_mat, data_path_src, save_path, dataset_type=label, generate_npy=args.generate_npy, debug_mode=args.debug_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
